## convVIT_tiny_pretext_manual_imageprocessor_batch_50_ep_70.keras
## unfrozen (trainable)


import tensorflow as tf
from tensorflow.keras import layers, Input, Model
from tensorflow.keras.optimizers import Adam


# Downstream encoder - using pretraining_model.encoder for feature extraction
class ConvNeXtEncoder(tf.keras.Model):
    def __init__(self, pretraining_encoder, **kwargs):
        super(ConvNeXtEncoder, self).__init__(**kwargs)
        self.encoder = pretraining_encoder  # Use pretraining_model.encoder

    def call(self, inputs):
        # Ensure inputs have the shape (B, H, W, C)
        pixel_values = tf.transpose(inputs, perm=[0, 1, 2, 3])  # (B, 3, 224, 224)
        outputs = self.encoder(pixel_values)

        # Debugging: check if `outputs` contains 'pooler_output' or 'last_hidden_state'
        if isinstance(outputs, dict):
            if 'pooler_output' in outputs:
                pooled_output = outputs['pooler_output']  # shape: (B, hidden_dim) # Use pooler_output instead of last_hidden_state
            else:
                pooled_output = outputs['last_hidden_state']  # use last_hidden_state if pooler_output is not available
        else:
            pooled_output = outputs  # assuming outputs is already the desired tensor

        return pooled_output

# Input layer
inputs = Input(shape=(224, 224, 3), name='pixel_values')


encoder = ConvNeXtEncoder(pretraining_encoder=pretraining_model.encoder)
features = encoder(inputs)

# Projection head (same as contrastive pretext head)
x_cls = layers.Dense(128, activation='relu')(features)
x_cls = layers.Dropout(0.2)(x_cls)
classification_output = layers.Dense(5, activation='softmax')(x_cls)

#model = Model(inputs=inputs, outputs=outputs)
#model.compile(optimizer=tf.keras.optimizers.Adam(), loss='categorical_crossentropy', metrics=['accuracy'])
#history = model.fit(labeled_train_dataset, epochs=10, validation_data=val_dataset)



# --- Decoder Head ---
# Project feature vector to a feature map
x = layers.Dense(7 * 7 * 128, activation='relu')(x_cls)  # You can change this size as needed
x = layers.Reshape((7, 7, 128))(x)

x = layers.UpSampling2D(size=(2, 2))(x)  # 7x7 → 14x14
x = layers.Conv2DTranspose(128, (3, 3), activation='relu', padding='same')(x)

x = layers.UpSampling2D(size=(2, 2))(x)  # 14x14 → 28x28
x = layers.Conv2DTranspose(64, (3, 3), activation='relu', padding='same')(x)

x = layers.UpSampling2D(size=(2, 2))(x)  # 28x28 → 56x56
x = layers.Conv2DTranspose(32, (3, 3), activation='relu', padding='same')(x)

x = layers.UpSampling2D(size=(2, 2))(x)  # 56x56 → 112x112
x = layers.Conv2DTranspose(16, (3, 3), activation='relu', padding='same')(x)

x = layers.UpSampling2D(size=(2, 2))(x)  # 112x112 → 224x224
decoder_output = layers.Conv2DTranspose(3, (3, 3), activation='sigmoid', padding='same')(x)   # Final output (224, 224, 3)

# Final model
model = Model(inputs=inputs, outputs=[classification_output, decoder_output])


model.compile(
    optimizer=Adam(),
    loss={
        'classification_output': 'categorical_crossentropy',
        'reconstruction_output': 'mse'
    },
    metrics={
        'classification_output': 'accuracy',
        'reconstruction_output': 'mse'
    }
)

history = model.fit(labeled_train_dataset, epochs=10, validation_data=val_dataset)








1 frames
/usr/local/lib/python3.11/dist-packages/keras/src/trainers/compile_utils.py in call(self, y_true, y_pred, sample_weight)
    753                             lambda _: "*", y_pred
    754                         )
--> 755                         raise ValueError(
    756                             "y_true and y_pred have different structures.\n"
    757                             f"y_true: {y_true_struct}\n"

ValueError: y_true and y_pred have different structures.
y_true: *
y_pred: ['*', '*']

